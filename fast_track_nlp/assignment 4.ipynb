{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1.\n",
        " Lexical Analysis and Morphological\n",
        "\n",
        "2. Syntactic Analysis (Parsing)\n",
        "\n",
        "3. Semantic Analysis\n",
        "\n",
        "4. Discourse Integration\n",
        "\n",
        "5. Pragmatic Analysis"
      ],
      "metadata": {
        "id": "i3H3Y3vAT3fr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.\n",
        "Word2Vec is used to convert text into vectors so they can be fed into neural networks. Because neural networks only take numerical data this is the only way."
      ],
      "metadata": {
        "id": "-Doi5BQhXU1O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.\n",
        "\n",
        "Bag-of-words: here we use the count of words that appear in the text.\n",
        "\n",
        "Tfidf: Here we calculate the term frequency-inverse document frequency for each word.\n",
        "\n",
        "Elmo: Here we pass the embedded text into cnn with max pooling followed by a high way network to flatten and then use bi-directional lstm. This is able to retrain contextual information. The networks used are pretrained"
      ],
      "metadata": {
        "id": "OX8B1v0DXU3M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.\n",
        "- Precision is the ratio between the True Positives and all the Positives.\n",
        "\n",
        "- Recall is the measure of our model correctly identifying True Positives."
      ],
      "metadata": {
        "id": "C7a8AhOaXU5f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.\n",
        "\n",
        "Tokenization is the process of tokenizing or splitting a string, text into a list of tokens. \n",
        "\n",
        "You may split:\n",
        "\n",
        "- Text into sentences \n",
        "- Sentences into words \n",
        "- Sentences using regular expressions "
      ],
      "metadata": {
        "id": "EJ07m81VXU8E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.\n",
        "\n",
        "Formal language does not use colloquialisms, contractions or first-person pronouns such as “I” or “We.” Informal language is more casual and spontaneous. It is used when communicating with friends or family either in writing or in conversation."
      ],
      "metadata": {
        "id": "ARLbVdSVXU-n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Xyst_jKlXVCD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BYK1YY_iXVHR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "a7JDjPf_T3hp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "]"
      ],
      "metadata": {
        "id": "XQXhC-XWT3lD"
      }
    }
  ]
}